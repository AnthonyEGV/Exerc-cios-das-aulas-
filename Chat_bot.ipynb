{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnthonyEGV/Exerc-cios-das-aulas-/blob/main/Chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo temos o instalador do google IA:"
      ],
      "metadata": {
        "id": "r2B2fe7ezbHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXS0f1okuuXM",
        "outputId": "6bb69c82-da80-4684-a4d9-649a0db2b03e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.15.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O bloco de c√≥ddigo abaixo temos a chave da API do Google Studio AI"
      ],
      "metadata": {
        "id": "10GLQpVmzhKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "61rJkOcQycWN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From serve para instalar parte de uma biblioteca ao inves de toda"
      ],
      "metadata": {
        "id": "T5M0KSdM1txn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n"
      ],
      "metadata": {
        "id": "gjioXZgX0hjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C√≥digo abaixo server para listar odas as apis do google"
      ],
      "metadata": {
        "id": "ygLH68mB2aX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "  print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDPG4xcc171d",
        "outputId": "a2602731-ca6f-42fa-854c-b95b818b4dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta se√ß√£o do c√≥digo demonstra como usar o modelo de IA do Google para gerar texto com base em um prompt fornecido."
      ],
      "metadata": {
        "id": "vxDMobt-4FmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = \"gemini-2.0-flash\"\n",
        "\n",
        "resposta = client.models.generate_content(model=modelo, contents= \"Quem √© a empresa por tr√° dos modelos Gemini?\")"
      ],
      "metadata": {
        "id": "GFFuXBAg2oyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1QIqIN-u3mBM",
        "outputId": "5d76afe0-e5bc-4b2c-da97-8e0635f9cb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A empresa por tr√°s dos modelos Gemini √© a **Google**.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model=modelo)\n",
        "\n",
        "resposta = chat.send_message(\"Oi, tudo bem?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FvPuPsUT3yCO",
        "outputId": "1d24bd13-a343-4f31-b99b-b195e1b3a6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tudo bem por aqui! üòä E com voc√™? Em que posso te ajudar hoje?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"Voc√™ √© um assistente pessoal e voc√™ sempre responde de forma sucinta. O que √© inteligencia artificial?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LmIO-bSM5S4G",
        "outputId": "fbc14cf4-cc9e-4cae-efe6-7e44e6c04792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Intelig√™ncia Artificial (IA) √© a capacidade de m√°quinas simularem a intelig√™ncia humana para realizar tarefas, aprender e resolver problemas.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "chat_config = types.GenerateContentConfig(\n",
        "    system_instruction = \"Voc√™ √© um assistente pessoal e voc√™ sempre responde de forma sucinta\",\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model=modelo, config=chat_config)"
      ],
      "metadata": {
        "id": "8862oDYt6Bio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"Voc√™ consegue criar um pc bom e barato?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "luCBhSCs7r57",
        "outputId": "ca0d3dad-80ed-4172-8cb3-0935b2967b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sim, consigo. Para um PC bom e barato, recomendo:\\n\\n*   **Processador:** AMD Ryzen 5 5600G\\n*   **Placa-m√£e:** A520M\\n*   **Mem√≥ria RAM:** 16GB DDR4 3200MHz\\n*   **Armazenamento:** SSD 500GB NVMe\\n*   **Fonte:** 450W 80+ Bronze\\n*   **Gabinete:** Um modelo simples e com boa ventila√ß√£o.\\n\\nEssa configura√ß√£o √© ideal para tarefas do dia a dia, estudos e at√© alguns jogos.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DpRgCa98XVO",
        "outputId": "55aceaed-0a5c-4856-8d65-af853b6e7e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Voc√™ consegue criar um pc bom e barato?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Sim, consigo. Para um PC bom e barato, recomendo:\\n\\n*   **Processador:** AMD Ryzen 5 5600G\\n*   **Placa-m√£e:** A520M\\n*   **Mem√≥ria RAM:** 16GB DDR4 3200MHz\\n*   **Armazenamento:** SSD 500GB NVMe\\n*   **Fonte:** 450W 80+ Bronze\\n*   **Gabinete:** Um modelo simples e com boa ventila√ß√£o.\\n\\nEssa configura√ß√£o √© ideal para tarefas do dia a dia, estudos e at√© alguns jogos.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input('Esperando prompt: ')\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  resposta = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", resposta.text)\n",
        "  print(\"\\n\\n\")\n",
        "  prompt = input('Esperando prompt: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpEWvXsK8qxQ",
        "outputId": "b01b73d2-4de7-4c9a-9627-d938b5864399"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: Quem foi Ayrton Senna?\n",
            "Resposta:  Ayrton Senna foi um piloto de F√≥rmula 1 brasileiro, amplamente considerado um dos maiores de todos os tempos. Foi tricampe√£o mundial e conhecido por sua habilidade excepcional em condi√ß√µes de chuva e sua determina√ß√£o.\n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: ele ganhou quantas vezes?\n",
            "Resposta:  Ayrton Senna foi campe√£o mundial de F√≥rmula 1 tr√™s vezes (1988, 1990 e 1991).\n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: Qual foi minha primeira pergunta?\n",
            "Resposta:  Sua primeira pergunta foi: \"Voc√™ consegue criar um pc bom e barato?\"\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqPdi0MI-R1Q",
        "outputId": "d52dd10e-a02c-4739-bf27-7266d09c1cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Voc√™ consegue criar um pc bom e barato?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Sim, consigo. Para um PC bom e barato, recomendo:\\n\\n*   **Processador:** AMD Ryzen 5 5600G\\n*   **Placa-m√£e:** A520M\\n*   **Mem√≥ria RAM:** 16GB DDR4 3200MHz\\n*   **Armazenamento:** SSD 500GB NVMe\\n*   **Fonte:** 450W 80+ Bronze\\n*   **Gabinete:** Um modelo simples e com boa ventila√ß√£o.\\n\\nEssa configura√ß√£o √© ideal para tarefas do dia a dia, estudos e at√© alguns jogos.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Quem te criou?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Eu sou um modelo de linguagem grande, treinado pelo Google.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Qual seu nome?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Eu n√£o tenho um nome.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Quem foi Ayrton Senna?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Ayrton Senna foi um piloto de F√≥rmula 1 brasileiro, amplamente considerado um dos maiores de todos os tempos. Foi tricampe√£o mundial e conhecido por sua habilidade excepcional em condi√ß√µes de chuva e sua determina√ß√£o.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='ele ganhou quantas vezes?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Ayrton Senna foi campe√£o mundial de F√≥rmula 1 tr√™s vezes (1988, 1990 e 1991).')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Qual foi minha primeira pergunta?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Sua primeira pergunta foi: \"Voc√™ consegue criar um pc bom e barato?\"\\n')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_config_2 = types.GenerateContentConfig(\n",
        "    system_instruction = \"Voc√™ √© um assistente pessoal e voc√™ sempre reponde de forma muito sarc√°stico\",\n",
        ")\n",
        "\n",
        "chat_2 = client.chats.create(model=modelo, config=chat_config)"
      ],
      "metadata": {
        "id": "X8Cn8RvE_imN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat_2.send_message(\"Voc√™ consegue criar um pc bom e barato?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "QtVKi0AA_nRs",
        "outputId": "a46472b5-86f2-44aa-c165-6fcf9dc91d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sim, consigo. Para um PC bom e barato, focaremos em componentes que oferecem o melhor custo-benef√≠cio. Aqui est√° uma sugest√£o:\\n\\n*   **Processador:** AMD Ryzen 5 5600G (integrado com placa de v√≠deo)\\n*   **Placa-m√£e:** Chipset A520\\n*   **Mem√≥ria RAM:** 16GB DDR4 3200MHz\\n*   **Armazenamento:** SSD 500GB NVMe\\n*   **Fonte:** 450W (certifica√ß√£o 80 Plus)\\n*   **Gabinete:** Um modelo simples e funcional\\n\\nEssa configura√ß√£o √© ideal para tarefas di√°rias, estudos e at√© alguns jogos leves.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}